{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaviBenshimol/Offensive_AI_Course/blob/main/OAI_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFQpOGtBCaaC"
      },
      "source": [
        "# Offensive AI Course Homework\n",
        "* Course website: https://ymirsky.github.io/course/\n",
        "* Course edition: Fall 2024\n",
        "* Lecturer: Dr. Yisroel Mirsky\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this homework you will attempt to perform a membership inference attack (MIA).\n",
        "\n",
        "### Steps\n",
        "1. Use the code provided below to train a model on the training set for CIFAR10.\n",
        "2. Impliment a Membership Inference Attack on the trained model using the provided CIFAR10 test set.\n",
        "3. Evalaute your attacks performance using the grading cell below. You must achive at least 0.50 accuracy (random guess) to obtain a grade.\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "* This homework can be done in groups of two\n",
        "* Make a copy of this notebook and solve it\n",
        "* Your attack must be a black box attack: After you train the model, you may only use it to produce predictions (vector of confidences).\n",
        "* You may use any papers, methods (novel or known), libraries, ART, github repos, and auxilalry datasets (aside from CIFAR) to help you perform the MIA attack.\n",
        "* Submission: (1) generate a sharable link to your notebook, (2) submit your link by [clicking here](https://docs.google.com/forms/d/e/1FAIpQLSeMrBCmpCPzOthLySlKfYCarnyqD7_KlKoYNGEAE9_conxp2Q/viewform?usp=sf_link)  \n",
        "* Deadline: submit your homework no later than January 14th. Each day past January 14th is -15 pnts\n",
        "\n",
        "\n",
        "For a list of all membership inference attack papers, you can take a look here:\n",
        "https://github.com/HongshengHu/membership-inference-machine-learning-literature\n",
        "\n",
        "The shadow models & attack model MI attack paper: https://arxiv.org/pdf/1610.05820.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Hj8YFcC2vv"
      },
      "source": [
        "# Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIZjF5vDN1Wt"
      },
      "outputs": [],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE2cbKSmGQcz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnEryi2JC_kk"
      },
      "source": [
        "## Import all libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zd4rQqpC_AF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMS7JwJxVkkV"
      },
      "source": [
        "## CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXr1e2YFVjCU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "ATTACK_RATIO_SPLIT = 0.5 # This is a float that you will decide. 0.5 will mean half of the data will be used to train / evaulate the model, the other half for evaulate the attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "707z_AaGilDw"
      },
      "source": [
        "# Target dataset - CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C8j-3HpipvY"
      },
      "source": [
        "## Load the dataset:\n",
        "\n",
        "1. The trian set will be split to train and shadow train (i.e. 2 train sets). The shadow train set will be used to train the shadow models.\n",
        "2. The test set will be used to evaluate your attack.\n",
        "\n",
        "You may choose what ever split you decide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuJdNEbpSFpr"
      },
      "source": [
        "**Pay attention you are not allowed to use the test set at all during the attack. It will only be used to evaulate your attack.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j69Qf1KQVDX"
      },
      "outputs": [],
      "source": [
        "train_data = CIFAR10(root='./data', train=True, download=True)\n",
        "test_data = CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "\n",
        "# For using the shadow models, use the SHADOW_MODEL_SPLIT to split the dataset\n",
        "# into train,test, shadow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3kLL2-8TfFX"
      },
      "outputs": [],
      "source": [
        "# Creating a list of all the class labels\n",
        "class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "               5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "# Visualizing some of the images from the training dataset\n",
        "plt.figure(figsize=[10,10])\n",
        "for i in range (25):    # for first 25 images\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_data[i][0], cmap=plt.cm.binary)\n",
        "  plt.xlabel(class_names[train_data[i][1]])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCxjb661hNO1"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1bfm3Ut6faS"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zgw_SI06faS"
      },
      "outputs": [],
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load CIFAR-10 (downloads if not found in './data')\n",
        "full_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "full_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Combine train and test sets into one big dataset\n",
        "all_data = []\n",
        "all_targets = []\n",
        "\n",
        "for img, lbl in full_train:\n",
        "    all_data.append(img)\n",
        "    all_targets.append(lbl)\n",
        "\n",
        "for img, lbl in full_test:\n",
        "    all_data.append(img)\n",
        "    all_targets.append(lbl)\n",
        "\n",
        "all_data = torch.stack(all_data)    # shape: [60000, 3, 32, 32]\n",
        "all_targets = torch.tensor(all_targets) # shape: [60000]\n",
        "\n",
        "indices = torch.randperm(len(all_data))[:]\n",
        "x_all = all_data[indices]\n",
        "y_all = all_targets[indices]\n",
        "\n",
        "train_size = len(x_all) * ATTACK_RATIO_SPLIT\n",
        "test_size = len(x_all) - train_size\n",
        "\n",
        "# Split into train/test\n",
        "x_train = all_data[:train_size]\n",
        "y_train = all_targets[:train_size]\n",
        "x_test = all_data[train_size:]\n",
        "y_test = all_targets[train_size:]\n",
        "\n",
        "\n",
        "# Create Datasets and DataLoaders\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrpB8eNPbhu9"
      },
      "source": [
        "# Training the NN classifier\n",
        "\n",
        "You can use Keras or Pytorch. You can use pretrained models if you wish to.\n",
        "\n",
        "**Minimum Accuracy on the train set: 0.62**\n",
        "\n",
        "**Minimum Accuracy on the test set: 0.62**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHsPbpUq6faS"
      },
      "outputs": [],
      "source": [
        "# Set as needed\n",
        "\n",
        "epochs = 100\n",
        "s = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcqQwcwMjHNJ"
      },
      "outputs": [],
      "source": [
        "class TargetModel(nn.Module):\n",
        "    def __init__(self, s=32, num_classes=10):\n",
        "        super(TargetModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, s, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(s, s, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(s, 2*s, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(2*s, 2*s, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.fc = nn.Linear(2*s*8*8, 2*s)  # After two pools, 32x32 -> 8x8 if no stride/pad reduces dimension except pooling\n",
        "        self.out = nn.Linear(2*s, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.out(x)  # raw logits\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3z5jrI46faS"
      },
      "outputs": [],
      "source": [
        "classifier = TargetModel(s=s, num_classes=num_classes).cuda()\n",
        "\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.5,0.99), eps=1e-8, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()  # categorical cross-entropy for logits\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    classifier.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    train_acc = correct_train / total_train\n",
        "\n",
        "    # Evaluate on test set every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        classifier.eval()\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = classifier(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "                total_test += labels.size(0)\n",
        "        test_acc = correct_test / total_test\n",
        "\n",
        "        print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "        # Save the classifier weights\n",
        "        torch.save(classifier.state_dict(), f\"model_epoch_{epoch}.pth\")\n",
        "    else:\n",
        "        # Print training accuracy and loss every epoch\n",
        "        print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGJreWa66faS"
      },
      "outputs": [],
      "source": [
        "# Evaluation of the target model on the test set.\n",
        "# This should be around 0.62-0.7\n",
        "\n",
        "classifier.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = classifier(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "        total_test += labels.size(0)\n",
        "test_acc = correct_test / total_test\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Mmv4coavH3"
      },
      "source": [
        "# Blackbox MIA Attack\n",
        "\n",
        "Utilizing as many attacks as possible can help you establish a baseline and select the most effective attack. I encourage you to let me view every attack and experiment you conducted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBVu8Smfa2_K"
      },
      "source": [
        "## Bad Example attack\n",
        "\n",
        "This is an example of a bad way to preform the attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDzkicsklnrb"
      },
      "outputs": [],
      "source": [
        "class MIAttack:\n",
        "\n",
        "  def __init__(self, classifier):\n",
        "    self.estimator = classifier\n",
        "\n",
        "  def fit(self, x,y):\n",
        "    # Code here\n",
        "    # Not mandatory to use it.\n",
        "    pass\n",
        "\n",
        "  def infer(self, x,y):\n",
        "    \"\"\"\n",
        "    This implementation uses the simple rule: if the model's prediction for a sample is correct, then it is a\n",
        "    member. Otherwise, it is not a member.\n",
        "    \"\"\"\n",
        "    # get model's predictions for x\n",
        "    y_pred = self.estimator.predict(x)\n",
        "    predicted_class = (np.argmax(y, axis=1) == np.argmax(y_pred, axis=1)).astype(int)\n",
        "    return predicted_class\n",
        "\n",
        "attack = MIAttack(classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uX2bJuIXCqE"
      },
      "source": [
        "## Your attack\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze6zh4n-XCU0"
      },
      "outputs": [],
      "source": [
        "class MIAttack:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def fit(self, x,y):\n",
        "    # Code here\n",
        "    # Not mandatory to use it.\n",
        "    pass\n",
        "\n",
        "  def infer(self, x,y):\n",
        "    # Code here\n",
        "    pass\n",
        "\n",
        "\n",
        "attack = MIAttack(classifier,...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuFn7-LaOcwZ"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Evaluate your attack on your IN (training set members) and OUT (non-members) data\n",
        "\n",
        "\n",
        "Accuracy + Grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y90b21jRXLDD"
      },
      "outputs": [],
      "source": [
        "def attack_score(attack, x_member,y_member, x_non_member, y_not_member):\n",
        "  inferred_train = attack.infer(x_member, y_member)\n",
        "  inferred_test = attack.infer(x_non_member, y_not_member)\n",
        "\n",
        "  # check accuracy\n",
        "  train_acc = np.sum(inferred_train) / len(inferred_train)\n",
        "  test_acc = 1 - (np.sum(inferred_test) / len(inferred_test))\n",
        "  acc = (train_acc * len(inferred_train) + test_acc * len(inferred_test)) / (len(inferred_train) + len(inferred_test))\n",
        "  print(f\"Members Accuracy: {train_acc:.4f}\")\n",
        "  print(f\"Non Members Accuracy {test_acc:.4f}\")\n",
        "  print(f\"Attack Accuracy {acc:.4f}\")\n",
        "  return train_acc, test_acc, acc\n",
        "\n",
        "\n",
        "train_acc, test_acc, acc = attack_score(attack, x_train, y_train, x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UlU0TIO6faT"
      },
      "outputs": [],
      "source": [
        "def attack_grade(train_acc, test_acc, accuracy):\n",
        "    random_guess = 0.50\n",
        "    naive_solution = 0.60\n",
        "    baseline_acc = 0.68\n",
        "\n",
        "    baseline_test_acc = 0.47\n",
        "    baseline_train_acc = 0.89\n",
        "\n",
        "    if accuracy < random_guess:\n",
        "        print(\"Grade: 60\")\n",
        "    elif random_guess <= accuracy <= naive_solution:\n",
        "        print(\"Grade: 75\")\n",
        "    elif naive_solution < accuracy <= 0.62:\n",
        "        print(\"Grade: 80\")\n",
        "    elif 0.62 < accuracy <= 0.65:\n",
        "        print(\"Grade: 85\")\n",
        "    elif 0.65 < accuracy <= baseline_acc:\n",
        "        if train_acc < 0.86 or test_acc < 0.45:\n",
        "            print(\"Grade: 85\")\n",
        "        else:\n",
        "            print(\"Grade: 90\")\n",
        "    elif accuracy > baseline_acc:\n",
        "        if train_acc < baseline_train_acc or test_acc < baseline_test_acc:\n",
        "            print(\"Grade: 90\")\n",
        "        else:\n",
        "            print(\"Grade: 100\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vcEJdOTnrKZ"
      },
      "source": [
        "# To submit you result, fill the following form:\n",
        "\n",
        "https://docs.google.com/forms/d/e/1FAIpQLSeszLBTxYBVfWpu9AOeFjPQJH393SilSMth_RBzET3QIEMDVQ/viewform?usp=sharing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "bio",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}